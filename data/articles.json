[{"title":"Europe seeks to limit use of AI in society","date":"Wed, April 14, 2021","text":"The use of facial recognition for surveillance, or algorithms that manipulate human behaviour, will be banned under proposed EU regulations on artificial intelligence. The wide-ranging proposals, which were leaked ahead of their official publication, also promised tough new rules for what they deem high-risk AI. That includes algorithms used by the police and in recruitment. Experts said the rules were vague and contained loopholes. The use of AI in the military is exempt, as are systems used by authorities in order to safeguard public security. The suggested list of banned AI systems includes: those designed or used in a manner that manipulates human behaviour, opinions or decisions ...causing a person to behave, form an opinion or take a decision to their detriment AI systems used for indiscriminate surveillance applied in a generalised manner AI systems used for social scoring those that exploit information or predictions and a person or group of persons in order to target their vulnerabilities European policy analyst Daniel Leufer tweeted that the definitions were very open to interpretation. 'How do we determine what is to somebody's detriment? And who assesses this?' he wrote. For AI deemed to be high risk, member states would have to apply far more oversight, including the need to appoint assessment bodies to test, certify and inspect these systems. And any companies that develop prohibited services, or fail to supply correct information about them, could face fines of up to 4% of their global revenue, similar to fines for GDPR breaches. High-risk examples of AI include: systems which establish priority in the dispatching of emergency services systems determining access to or assigning people to educational institutes recruitment algorithms those that evaluate credit worthiness those for making individual risk assessments crime-predicting algorithms Mr Leufer added that the proposals should 'be expanded to include all public sector AI systems, regardless of their assigned risk level'. 'This is because people typically do not have a choice about whether or not to interact with an AI system in the public sector.'  Sloppy and dangerous Meanwhile Michael Veale, a lecturer in digital rights and regulation at University College London, highlighted a clause that will force organisations to disclose when they are using deepfakes, a particularly controversial use of AI to create fake humans or to manipulate images and videos of real people. He also told the BBC that the legislation was primarily 'aimed at vendors and consultants selling - often nonsense- AI technology to schools, hospitals, police and employers'. But he added that tech firms who used AI 'to manipulate users' may also have to change their practices. With this legislation, the EC has had to walk a difficult tightrope between ensuring AI is used for what it calls 'a tool... with the ultimate aim of increasing human wellbeing', and also ensuring it doesn't stop EU countries competing with the US and China over technological innovations. And it acknowledged that AI already informed many aspects of our lives. The European Centre for Not-for-Profit Law, which had contributed to the European Commission's White Paper on AI, told the BBC that there was 'lots of vagueness and loopholes' in the proposed legislation. 'The EU's approach to binary-defining high versus low risk is sloppy at best and dangerous at worst, as it lacks context and nuances needed for the complex AI ecosystem already existing today. 'First, the commission should consider risks of AI systems within a rights-based framework - as risks they pose to human rights, rule of law and democracy. 'Second, the commission should reject an oversimplified low-high risk structure and consider a tier-based approach on the levels of AI risk.' The details could change again before the rules are officially unveiled next week. And it is unlikely to become law for several more years."}, 
{"title":"The EU is considering a ban on AI for mass surveillance and social credit scores", "date":"April 14, 2021", "text":"The European Union is considering banning the use of artificial intelligence for a number of purposes, including mass surveillance and social credit scores. This is according to a leaked proposal that is circulating online, first reported by Politico, ahead of an official announcement expected next week. If the draft proposal is adopted, it would see the EU take a strong stance on certain applications of AI, setting it apart from the US and China. Some use cases would be policed in a manner similar to the EU’s regulation of digital privacy under GDPR legislation. Member states, for example, would be required to set up assessment boards to test and validate high-risk AI systems. And companies that develop or sell prohibited AI software in the EU — including those based elsewhere in the world — could be fined up to 4 percent of their global revenue. According to a copy of the draft seen by The Verge, the draft regulations include: A ban on AI for “indiscriminate surveillance,” including systems that directly track individuals in physical environments or aggregate data from other sources A ban on AI systems that create social credit scores, which means judging someone’s trustworthiness based on social behavior or predicted personality traits  Special authorization for using “remote biometric identification systems” like facial recognition in public spaces Notifications required when people are interacting with an AI system, unless this is “obvious from the circumstances and the context of use” New oversight for “high-risk” AI systems, including those that pose a direct threat to safety, like self-driving cars, and those that have a high chance of affecting someone’s livelihood, like those used for job hiring, judiciary decisions, and credit scoring Assessment for high-risk systems before they’re put into service, including making sure these systems are explicable to human overseers and that they’re trained on “high quality” datasets tested for bias The creation of a “European Artificial Intelligence Board,” consisting of representatives from every nation-state, to help the commission decide which AI systems count as “high-risk” and to recommend changes to prohibitions Perhaps the most important section of the document is Article 4, which prohibits certain uses of AI, including mass surveillance and social credit scores. Reactions to the draft from digital rights groups and policy experts, though, say this section needs to be improved. “The descriptions of AI systems to be prohibited are vague, and full of language that is unclear and would create serious room for loopholes,” Daniel Leufer, Europe policy analyst at Access Now, told The Verge. That section, he says, is “far from ideal.” Leufer notes that a prohibition on systems that cause people to “behave, form an opinion or take a decision to their detriment” is unhelpfully vague. How exactly would national laws decide if a decision was to someone’s detriment or not? On the other hand, says Leufer, the prohibition against AI for mass surveillance is “far too lenient.” He adds that the prohibition on AI social credit systems based on “trustworthiness” is also defined too narrowly. Social credit systems don’t have to assess whether someone is trustworthy to decide things like their eligibility for welfare benefits. On Twitter, Omer Tene, vice president of nonprofit IAPP (The International Association of Privacy Professionals), commented that the regulation “represents the typical Brussels approach to new tech and innovation. When in doubt, regulate.” If the proposals are passed, said Tene, it will create a “vast regulatory ecosystem,” which would draw in not only the creators of AI systems, but also importers, distributors, and users, and create a number of regulatory boards, both national and EU-wide. This ecosystem, though, wouldn’t primarily be about restraining “big tech,” says Michael Veale, a lecturer in digital rights and regulations at University College London. “In its sights are primarily the lesser known vendors of business and decision tools, whose work often slips without scrutiny by either regulators or their own clients,” Veale tells The Verge. “Few tears will be lost over laws ensuring that the few AI companies that sell safety-critical systems or systems for hiring, firing, education and policing do so to high standards. Perhaps more interestingly, this regime would regulate buyers of these tools, for example to ensure there is sufficiently authoritative human oversight.” It’s not known what changes might have been made to this draft proposal as EU policymakers prepare for the official announcement on April 21st. Once the regulation has been proposed, though, it will be subject to changes following feedback from MEPs and will have to be implemented separately in each nation-state."},
{"title":"2020 was a record year of growth for Lytx", "date":"APR 14, 2021", "text":"A pandemic couldn’t slow popular transportation technology last year. Lytx set a new revenue record in 2020, driven by a 63% increase in new customers along with more demand from its current clients, the transportation technology company announced on April 14. The video telematics company, which is powered by machine vision and artificial intelligence (MV+AI) technology, also reported its growth trajectory continued in Q1 2021. During the first three months of this year, Lytx reporting a new quarterly record of more than 100,000 new and upgraded subscriptions to its technology. “In a year filled with uncertainty, we accelerated our growth by focusing on delivering value to clients as they rose to the challenge brought on by the global crises of 2020,” Brandon Nixon, chairman and CEO of Lytx, said. Lytx continued to expand its global team and increase investment in research and development by 27% in 2020, which the company credited with fueling innovations to drive it through the next decade. The increased demand for transportation solutions, according to Lytx press release, affirmed the company’s strong financial standing. Berg Insight’s 2021 market report named Lytx the global leader in video telematics with an estimated 700,000 subscriptions – two times the size of the company’s nearest competitor. “Thanks to the largest-ever investment in video telematics from Permira that valued Lytx in excess of $2.5 billion,” Nixon said, “We were able to drive even greater investment in our capabilities to help fleets improve their operations, enhance their profitability, and better protect their most valuable assets – their employees.” With the record revenue in 2020, Lytx added nearly 750 new clients — a 63% increase over new customers it signed up in 2019 — including Coca-Cola Beverages Florida, the Kroger Fulfillment Network, Badger Daylighting Corp., Foodliner Inc., Love’s Travel Stops and Country Stores Inc., and Lyreco UK. Lytx also is reporting a 105% increase in bookings of small business clients. The company also said it upgraded a record 125,000 vehicles to Lytx’s MV+AI technology, expanding on an existing client base leveraging the company’s most advanced offering. The company completed 180,000 installations in 2020, the most it had ever done in one calendar year. Among the other larger fleets that have long-term commitments with Lytx — through upgrades or expansions — include Waste Management National Services Inc., Waste Connections Inc., AmeriGas Propane, ARS Corp., Ryder Integrated Logistics, U.S. Xpress Enterprises, and Ruan Transportation Management Systems. Lytx reported that it boosted R&D spending by 27% in 2020 over the prior year, making innovation by far the company’s single greatest area of investment. It also acquired the Surfsight product line to expand distribution channels in global markets. Lytx MV+AI expands Using technology it has been developing for more than a decade to identify and capture in-vehicle risk with unmatched accuracy, Lytx expanded its MV+AI offerings last year. It enhanced its offering by adding the capability to detect five additional behaviors using MV+AI: handheld device, no seat belt, food or drink, driver smoking, and inattentiveness. With MV+AI, Lytx said that fleets are able to detect risks much more quickly — in some cases as much as 21 times faster — than relying on accelerometer data alone. In addition, pairing MV+AI with real-time audio alerts helped select clients immediately reduce risky behaviors, such as handheld device use, by as much as 50%, the company reported.  Throughout 2020, Lytx added 33 billion miles of commercial driving data, bringing the total number of driving miles analyzed by Lytx to over 150 billion. The company leveraged the insights generated by its data to drive unmatched accuracy in its risk-detection algorithms and fuel product development. Among the many innovations released this past year: Launched Lytx Lab, a first-of-its-kind data dashboard that gives clients access to view risk maps, plot vehicle trips around risk points, and check traffic or weather with near real-time road view images from more than 350,000 cameras. Paired driver-view MV+AI triggers with real-time, in-vehicle alerts that help drivers recognize patterns of risky driving and self-correct in the moment. Introduced the ability to quantify the duration and percentage of drive time a driver engaged in risky behavior, using MV+AI to provide a more complete view of risk. Developed Risk ID Without Recording to detect patterns of risky driving without recording video of the driver, an industry-first feature offering additional privacy for drivers. Launched the Lytx Driver App, designed to help drivers take charge of their driving safety by reviewing their own video and performance stats. Added Lytx Badge driver identification capabilities using machine vision to detect QR codes, making it easier for fleets to manage driver-to-vehicle assignments. Released the Lytx Unassigned Drive Time service, a first-of-its-kind offering designed to save fleets time, reduce labor costs, and improve ELD compliance. Advanced integration features that enable best-in-class video services with Geotab application and ELD. Looking ahead In 2021 So far, things have not slowed down for Lytx in 2021. The company reported strong Q1 results that include a new quarterly sales record of more than 100,000 new and upgrade subscriptions."},
{"title":"Machine Learning May Help To Curb Future Epidemics: Study.", "date":"April 14, 2021", "text":"Machine Learning (ML) can be used to find effective testing methods during epidemic outbreaks, thereby helping to better control the outbreaks, a new study said. ML is a type of Artificial Intelligence and can be described as a mathematical model where computers are trained to learn to see connections and solve problems using different data sets. The team from the University of Gothenburg in Sweden developed a method to improve testing strategies during epidemic outbreaks and to predict which individuals require the need for testing, even with relatively limited information. In the study, data about the infected individual’s network of contacts and other information were used: Who they have been in close contact with, where and for how long. The researchers found that the outbreak can quickly be brought under control when the method is used, while random testing leads to the uncontrolled spread of the outbreak with many more infected individuals. Under real-world conditions, the information can be added, such as demographic data and age and health-related conditions, which can improve the method’s effectiveness even more. The same method can also be used to prevent reinfections in the population if immunity after the disease is only temporary, the researchers said. Machine Learning (ML) can be used to find effective testing methods during epidemic outbreaks, thereby helping to better control the outbreaks, a new study said. Pixabay “This can be a first step towards the society gaining better control of future major outbreaks and reducing the need to shut down society,” said the study’s lead author Laura Natali, a doctoral student of physics at the varsity. The method also has the potential to easily predict if a specific age group should be tested or if a limited geographical area is a risk zone, such as a school or a specific neighbourhood. “When a large outbreak begins, it is important to quickly and effectively identify the infectious individuals. In random testing, there is a significant risk of failing to achieve this, but with a more goal-oriented testing strategy, we can find more infected individuals and thereby also gain the necessary information to decrease the spread of the infection,” Natali said. “Machine Learning can be used to develop this type of testing strategy,” she added. (IANS/KR)."}]